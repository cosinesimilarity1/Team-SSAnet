/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Traceback (most recent call last):
  File "/local/scratch/shared-directories/ssanet/SCRIPTS/main_training.py", line 156, in <module>
    mp.spawn(mp_fn,
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 246, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 202, in start_processes
    while not context.join():
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 163, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 74, in _wrap
    fn(i, *args)
  File "/local/scratch/shared-directories/ssanet/SCRIPTS/main_training.py", line 101, in mp_fn
    for step, data in enumerate(trainloader, 0):
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1325, in _next_data
    return self._process_data(data)
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/_utils.py", line 694, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 3.
Original Traceback (most recent call last):
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/local/scratch/shared-directories/ssanet/SCRIPTS/dataloaderfin.py", line 57, in __getitem__
    img_pp = self.preprocess_dicom_image(image_path)
  File "/local/scratch/shared-directories/ssanet/SCRIPTS/dataloaderfin.py", line 39, in preprocess_dicom_image
    dicom = pydicom.read_file(dicom_path)
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/pydicom/filereader.py", line 1002, in dcmread
    fp = open(fp, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: '/local/scratch/shared-directories/ssanet/embed-dataset-aws/images/cohort_2/66155381/1.2.842.113973.3.61.1.50870454.20150318.1134336/1.2.845.113682.2750824979.1426659760.4874.60991/1.2.826.0.1.3680043.8.498.13282791030612163760381790384251597699.dcm'


[2023-12-02 02:15:53,437] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 3885792) of binary: /local/scratch/shared-directories/ssanet/mlembed/bin/python
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/local/scratch/shared-directories/ssanet/mlembed/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/local/scratch/shared-directories/ssanet/SCRIPTS/main_training.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-12-02_02:15:53
  host      : h100server.mathcs.emory.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3885792)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
